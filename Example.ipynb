{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from complexLayers import ComplexBatchNorm2d, ComplexConv2d, ComplexLinear\n",
    "from complexLayers import ComplexDropout2d, NaiveComplexBatchNorm2d\n",
    "from complexFunctions import complex_relu, complex_max_pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = datasets.MNIST('../data', train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST('../data', train=False, transform=trans, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, 5, 1)\n",
    "        self.bn  = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, 5, 1)\n",
    "        self.fc1 = ComplexLinear(4*4*20, 500)\n",
    "        self.dropout = ComplexDropout2d(p = 0.3)\n",
    "        self.fc2 = ComplexLinear(500, 10)\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,4*4*20)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3, momentum=0.9)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target =data.to(device).type(torch.complex64), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {:3} [{:6}/{:6} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data), \n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.item())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/ 60000 (  0%)]\tLoss: 2.568596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spopoff/dev/complexPyTorch/complexFunctions.py:54: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370124688/work/aten/src/ATen/native/Copy.cpp:162.)\n",
      "  mask = torch.ones_like(input).type(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [  6400/ 60000 ( 11%)]\tLoss: 0.418056\n",
      "Train Epoch:   0 [ 12800/ 60000 ( 21%)]\tLoss: 0.069222\n",
      "Train Epoch:   0 [ 19200/ 60000 ( 32%)]\tLoss: 0.126281\n",
      "Train Epoch:   0 [ 25600/ 60000 ( 43%)]\tLoss: 0.198962\n",
      "Train Epoch:   0 [ 32000/ 60000 ( 53%)]\tLoss: 0.045389\n",
      "Train Epoch:   0 [ 38400/ 60000 ( 64%)]\tLoss: 0.044656\n",
      "Train Epoch:   0 [ 44800/ 60000 ( 75%)]\tLoss: 0.056991\n",
      "Train Epoch:   0 [ 51200/ 60000 ( 85%)]\tLoss: 0.114485\n",
      "Train Epoch:   0 [ 57600/ 60000 ( 96%)]\tLoss: 0.027030\n",
      "Train Epoch:   1 [     0/ 60000 (  0%)]\tLoss: 0.051180\n",
      "Train Epoch:   1 [  6400/ 60000 ( 11%)]\tLoss: 0.026171\n",
      "Train Epoch:   1 [ 12800/ 60000 ( 21%)]\tLoss: 0.072911\n",
      "Train Epoch:   1 [ 19200/ 60000 ( 32%)]\tLoss: 0.008332\n",
      "Train Epoch:   1 [ 25600/ 60000 ( 43%)]\tLoss: 0.047245\n",
      "Train Epoch:   1 [ 32000/ 60000 ( 53%)]\tLoss: 0.150064\n",
      "Train Epoch:   1 [ 38400/ 60000 ( 64%)]\tLoss: 0.129930\n",
      "Train Epoch:   1 [ 44800/ 60000 ( 75%)]\tLoss: 0.029466\n",
      "Train Epoch:   1 [ 51200/ 60000 ( 85%)]\tLoss: 0.034150\n",
      "Train Epoch:   1 [ 57600/ 60000 ( 96%)]\tLoss: 0.001661\n",
      "Train Epoch:   2 [     0/ 60000 (  0%)]\tLoss: 0.006464\n",
      "Train Epoch:   2 [  6400/ 60000 ( 11%)]\tLoss: 0.007788\n",
      "Train Epoch:   2 [ 12800/ 60000 ( 21%)]\tLoss: 0.007540\n",
      "Train Epoch:   2 [ 19200/ 60000 ( 32%)]\tLoss: 0.023180\n",
      "Train Epoch:   2 [ 25600/ 60000 ( 43%)]\tLoss: 0.107216\n",
      "Train Epoch:   2 [ 32000/ 60000 ( 53%)]\tLoss: 0.080173\n",
      "Train Epoch:   2 [ 38400/ 60000 ( 64%)]\tLoss: 0.020483\n",
      "Train Epoch:   2 [ 44800/ 60000 ( 75%)]\tLoss: 0.018006\n",
      "Train Epoch:   2 [ 51200/ 60000 ( 85%)]\tLoss: 0.016306\n",
      "Train Epoch:   2 [ 57600/ 60000 ( 96%)]\tLoss: 0.192334\n",
      "Train Epoch:   3 [     0/ 60000 (  0%)]\tLoss: 0.030158\n",
      "Train Epoch:   3 [  6400/ 60000 ( 11%)]\tLoss: 0.004021\n",
      "Train Epoch:   3 [ 12800/ 60000 ( 21%)]\tLoss: 0.045611\n",
      "Train Epoch:   3 [ 19200/ 60000 ( 32%)]\tLoss: 0.015569\n",
      "Train Epoch:   3 [ 25600/ 60000 ( 43%)]\tLoss: 0.003977\n",
      "Train Epoch:   3 [ 32000/ 60000 ( 53%)]\tLoss: 0.021426\n"
     ]
    }
   ],
   "source": [
    "# Run training on 4 epochs\n",
    "for epoch in range(4):\n",
    "    train(model, device, train_loader, optimizer, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
